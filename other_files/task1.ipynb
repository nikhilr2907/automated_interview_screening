{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06b1dc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d8e15",
   "metadata": {},
   "source": [
    "*** Feature Selection Pipeline ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e7e716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_info = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15f0d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reliability(df, feature, protected_characteristics=['Sex', 'Race'], n_twins=1000, distance='mahalanobis'):\n",
    "    \"\"\"\n",
    "    Assess feature reliability using distance-based twins method.\n",
    "    \n",
    "    1. Compute pairwise distances WITH the feature\n",
    "    2. Find twins: closest pairs based on distance\n",
    "    3. Compute pairwise distances WITHOUT the feature\n",
    "    4. Compare average distance for twins before and after removing the feature\n",
    "    \n",
    "    distance: 'mahalanobis' or 'euclidean'\n",
    "    \"\"\"\n",
    "\n",
    "    target = 'prior_hiring_decision'\n",
    "    \n",
    "    # Features excluding protected characteristics and target\n",
    "    all_features = [c for c in df.columns if c not in protected_characteristics + [target]]\n",
    "    \n",
    "    if feature not in all_features:\n",
    "        return None\n",
    "    \n",
    "    features_without = [f for f in all_features if f != feature]\n",
    "    \n",
    "    # Scale features\n",
    "    scaler_with = StandardScaler()\n",
    "    scaler_without = StandardScaler()\n",
    "    \n",
    "    X_with = scaler_with.fit_transform(df[all_features].values)\n",
    "    X_without = scaler_without.fit_transform(df[features_without].values)\n",
    "    \n",
    "    # Sample for efficiency if dataset is large\n",
    "    if len(df) > 2000:\n",
    "        idx = np.random.choice(len(df), 2000, replace=False)\n",
    "        X_with = X_with[idx]\n",
    "        X_without = X_without[idx]\n",
    "    \n",
    "    # Compute distances\n",
    "    if distance == 'mahalanobis':\n",
    "        # Use covariance matrix for Mahalanobis\n",
    "        cov_with = np.cov(X_with.T)\n",
    "        cov_without = np.cov(X_without.T)\n",
    "        try:\n",
    "            vi_with = np.linalg.inv(cov_with)\n",
    "            vi_without = np.linalg.inv(cov_without)\n",
    "            dist_with = cdist(X_with, X_with, metric='mahalanobis', VI=vi_with)\n",
    "            dist_without = cdist(X_without, X_without, metric='mahalanobis', VI=vi_without)\n",
    "        except np.linalg.LinAlgError:\n",
    "            # Fall back to euclidean if covariance is singular\n",
    "            dist_with = cdist(X_with, X_with, metric='euclidean')\n",
    "            dist_without = cdist(X_without, X_without, metric='euclidean')\n",
    "    else:\n",
    "        dist_with = cdist(X_with, X_with, metric='euclidean')\n",
    "        dist_without = cdist(X_without, X_without, metric='euclidean')\n",
    "    \n",
    "    # Find twins: for each point, find its closest neighbor (excluding itself)\n",
    "    np.fill_diagonal(dist_with, np.inf)\n",
    "    twin_indices = np.argmin(dist_with, axis=1)\n",
    "    \n",
    "    # Get distances for twin pairs\n",
    "    twin_dist_with = [dist_with[i, twin_indices[i]] for i in range(len(twin_indices))]\n",
    "    twin_dist_without = [dist_without[i, twin_indices[i]] for i in range(len(twin_indices))]\n",
    "    \n",
    "    avg_dist_with = float(np.mean(twin_dist_with))\n",
    "    avg_dist_without = float(np.mean(twin_dist_without))\n",
    "    \n",
    "    # Reliability: how much does removing the feature increase distance between twins\n",
    "    reliability_score = float(avg_dist_without - avg_dist_with)\n",
    "    \n",
    "    return {\n",
    "        'reliability_score': reliability_score,\n",
    "        'avg_twin_dist_with_feature': avg_dist_with,\n",
    "        'avg_twin_dist_without_feature': avg_dist_without,\n",
    "        'n_samples': int(len(X_with))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2142dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disparate_impact(df, feature, protected_characteristics=[\"Sex\", \"Race\"], threshold=0.8):\n",
    "    \"\"\"\n",
    "    Calculate disparate impact ratio for a feature across protected groups.\n",
    "    \n",
    "    Measures whether the feature values differ significantly between protected groups.\n",
    "    DI = mean(feature | unprivileged) / mean(feature | privileged)\n",
    "    \n",
    "    A ratio between 0.8 and 1.25 is generally considered acceptable (4/5ths rule).\n",
    "    \"\"\"\n",
    "    \n",
    "    X = df[feature]\n",
    "    results = {}\n",
    "    \n",
    "    for char in protected_characteristics:\n",
    "        C = df[char]\n",
    "        unique_vals = C.unique()\n",
    "        \n",
    "        if len(unique_vals) == 2:\n",
    "            # Binary protected characteristic\n",
    "            privileged = C == C.max()  # Assume higher value is privileged\n",
    "            unprivileged = ~privileged\n",
    "            \n",
    "            mean_privileged = float(X[privileged].mean())\n",
    "            mean_unprivileged = float(X[unprivileged].mean())\n",
    "            \n",
    "            if mean_privileged != 0:\n",
    "                ratio = mean_unprivileged / mean_privileged\n",
    "            else:\n",
    "                ratio = float('inf') if mean_unprivileged > 0 else 1.0\n",
    "                \n",
    "            results[char] = {\n",
    "                'ratio': float(ratio),\n",
    "                'mean_privileged': mean_privileged,\n",
    "                'mean_unprivileged': mean_unprivileged\n",
    "            }\n",
    "        else:\n",
    "            # Multi-class: compare each group to the majority/privileged group\n",
    "            privileged_val = int(C.value_counts().idxmax())  # Most common as reference\n",
    "            mean_privileged = float(X[C == privileged_val].mean())\n",
    "            \n",
    "            group_ratios = {}\n",
    "            for val in unique_vals:\n",
    "                if val != privileged_val:\n",
    "                    mean_group = float(X[C == val].mean())\n",
    "                    if mean_privileged != 0:\n",
    "                        group_ratios[int(val)] = float(mean_group / mean_privileged)\n",
    "                    else:\n",
    "                        group_ratios[int(val)] = float('inf') if mean_group > 0 else 1.0\n",
    "            \n",
    "            results[char] = {\n",
    "                'privileged_group': privileged_val,\n",
    "                'group_ratios': group_ratios,\n",
    "                'min_ratio': float(min(group_ratios.values())) if group_ratios else 1.0\n",
    "            }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "659516d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_features(filepath):\n",
    "    ###### Check validity on \n",
    "    protected_characteristics = [\"Age\", \"Sex\",\"Race\"]\n",
    "    reliable_features = {}\n",
    "    valid_features = {}\n",
    "    df = pandas.read_csv(filepath)\n",
    "    for col in [col for col in df.columns if col not in protected_characteristics and col != \"prior_hiring_decision\"]:\n",
    "        ###### Check correlation with prior hiring decision\n",
    "        print(col)\n",
    "        reliable_features[col] = reliability(df,col,protected_characteristics,0.1)\n",
    "        valid_features[col] = disparate_impact(df,col,protected_characteristics)\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "    return {\"reliability\": reliable_features, \"validity\": valid_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68762488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikhi\\Documents\\Imperial\\ethics\\automated_interview_screening\\other_files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c8291c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workclass\n",
      "Education\n",
      "Marital_Status\n",
      "Occupation\n",
      "Relationship\n",
      "Hours_Per_Week\n",
      "Place_Of_Birth\n",
      "interview_score\n",
      "cv_assessment_score\n",
      "Workclass\n",
      "Education\n",
      "Marital_Status\n",
      "Occupation\n",
      "Relationship\n",
      "Hours_Per_Week\n",
      "Place_Of_Birth\n",
      "interview_score\n",
      "cv_assessment_score\n",
      "Workclass\n",
      "Education\n",
      "Marital_Status\n",
      "Occupation\n",
      "Relationship\n",
      "Hours_Per_Week\n",
      "Place_Of_Birth\n",
      "interview_score\n",
      "cv_assessment_score\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data\"\n",
    "for path in os.listdir(data_path):\n",
    "    feature_info.append(valid_features(os.path.join(data_path, path)))\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8ac8ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open(\"feature_info.json\", \"w\") as f:\n",
    "    json.dump(feature_info, f,indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
