{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Equalized Odds**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalized_odds(data, pred_col='prediction', true_col='prior_hiring_decision'):\n",
    "    \"\"\"\n",
    "    Compute equalized odds for binary race (white=1 vs non-white=anything else).\n",
    "    TPR = P(pred=1 | true=1), FPR = P(pred=1 | true=0)\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    data['_race_binary'] = (data['Race'] == 1).astype(int)\n",
    "    \n",
    "    tpr_rates = []\n",
    "    fpr_rates = []\n",
    "    \n",
    "    for race in [0, 1]:  # 0=non-white, 1=white\n",
    "        group_data = data[data['_race_binary'] == race]\n",
    "        \n",
    "        # Actual positives and negatives\n",
    "        actual_positives = group_data[group_data[true_col] == 1]\n",
    "        actual_negatives = group_data[group_data[true_col] == 0]\n",
    "        \n",
    "        # TPR: of actual positives, how many predicted positive?\n",
    "        if len(actual_positives) > 0:\n",
    "            tpr = actual_positives[pred_col].mean()\n",
    "            tpr_rates.append(tpr)\n",
    "        \n",
    "        # FPR: of actual negatives, how many predicted positive?\n",
    "        if len(actual_negatives) > 0:\n",
    "            fpr = actual_negatives[pred_col].mean()\n",
    "            fpr_rates.append(fpr)\n",
    "    \n",
    "    max_tpr, min_tpr = max(tpr_rates), min(tpr_rates)\n",
    "    max_fpr, min_fpr = max(fpr_rates), min(fpr_rates)\n",
    "    \n",
    "    tpr_ratio = float('inf') if min_tpr == 0 else max_tpr / min_tpr\n",
    "    fpr_ratio = float('inf') if min_fpr == 0 else max_fpr / min_fpr\n",
    "    \n",
    "    return max(tpr_ratio, fpr_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Baseline Model Comparison (Neural Network)\n",
    "\n",
    "In this notebook, you will train a simple Neural Network (MLP) to predict the `prior_hiring_decision` target variable. Compare its performance to the previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mode: WEIGHTED\n",
      "Training Shape: (30000, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load Data\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "val_df = pd.read_csv('../data/val.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "# Configuration: Toggle between weighted and unweighted training\n",
    "USE_WEIGHTED = True  # Set to False for unweighted training\n",
    "\n",
    "columns_to_drop = [\"Hours_Per_Week\", \"Marital_Status\", \"Relationship\"]\n",
    "protected_characteristics = [\"Sex\", \"Race\", \"Age\", \"Place_Of_Birth\"]\n",
    "target = 'prior_hiring_decision'\n",
    "\n",
    "# Drop columns_to_drop\n",
    "for df in [train_df, val_df, test_df]:\n",
    "    df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "print(f\"Training mode: {'WEIGHTED' if USE_WEIGHTED else 'UNWEIGHTED'}\")\n",
    "print(\"Training Shape:\", train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Weights (applied to loss function):\n",
      "  Formula: w = P(race) * P(label) / P(race, label)\n",
      "\n",
      "  non-white, not hired: 0.8388\n",
      "  non-white, hired: 1.2625\n",
      "  white, not hired: 1.1321\n",
      "  white, hired: 0.8879\n"
     ]
    }
   ],
   "source": [
    "def compute_group_weights(df, label_col):\n",
    "    \"\"\"\n",
    "    Compute rebalancing weights for each (race_binary, label) combination.\n",
    "    Returns a dictionary mapping (race_binary, label) -> weight.\n",
    "    \n",
    "    Weight formula: w = P(race) * P(label) / P(race, label)\n",
    "    This makes race and label independent in the weighted distribution.\n",
    "    \"\"\"\n",
    "    total = len(df)\n",
    "    labels = df[label_col].unique()\n",
    "    \n",
    "    # Binary race: 1 = white, 0 = non-white\n",
    "    race_binary = (df['Race'] == 1).astype(int)\n",
    "    \n",
    "    weights = {}\n",
    "    for race in [0, 1]:\n",
    "        race_count = (race_binary == race).sum()\n",
    "        for label in labels:\n",
    "            label_count = (df[label_col] == label).sum()\n",
    "            intersection_count = ((race_binary == race) & (df[label_col] == label)).sum()\n",
    "            \n",
    "            if intersection_count > 0:\n",
    "                # w = P(race) * P(label) / P(race, label)\n",
    "                weight = (race_count * label_count) / (total * intersection_count)\n",
    "            else:\n",
    "                weight = 1.0\n",
    "            \n",
    "            weights[(race, int(label))] = float(weight)\n",
    "    \n",
    "    return weights\n",
    "\n",
    "\n",
    "def get_sample_weights(df, group_weights, label_col):\n",
    "    \"\"\"\n",
    "    Get per-sample weights array for use in loss function.\n",
    "    \"\"\"\n",
    "    race_binary = (df['Race'] == 1).astype(int)\n",
    "    sample_weights = [\n",
    "        group_weights.get((race, int(label)), 1.0)\n",
    "        for race, label in zip(race_binary, df[label_col])\n",
    "    ]\n",
    "    return np.array(sample_weights)\n",
    "\n",
    "\n",
    "# Compute group weights from training data\n",
    "group_weights = compute_group_weights(train_df, target)\n",
    "\n",
    "print(\"Group Weights (applied to loss function):\")\n",
    "print(\"  Formula: w = P(race) * P(label) / P(race, label)\")\n",
    "print()\n",
    "for (race, label), weight in sorted(group_weights.items()):\n",
    "    race_name = \"white\" if race == 1 else \"non-white\"\n",
    "    label_name = \"hired\" if label == 1 else \"not hired\"\n",
    "    print(f\"  {race_name}, {label_name}: {weight:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PyTorch classifier with sklearn-like API and sample weight support\n",
    "class TorchBinaryMLP:\n",
    "    def __init__(self,\n",
    "                 hidden_layer_sizes=(64,),\n",
    "                 alpha=0.0001,\n",
    "                 learning_rate_init=0.001,\n",
    "                 max_epochs=500,\n",
    "                 random_state=42,\n",
    "                 early_stopping=True,\n",
    "                 batch_size=256,\n",
    "                 patience=10,\n",
    "                 device=None):\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.alpha = alpha\n",
    "        self.learning_rate_init = learning_rate_init\n",
    "        self.max_epochs = max_epochs\n",
    "        self.random_state = random_state\n",
    "        self.early_stopping = early_stopping\n",
    "        self.batch_size = batch_size\n",
    "        self.patience = patience\n",
    "        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model_ = None\n",
    "        self.input_dim_ = None\n",
    "\n",
    "    def _build_model(self, input_dim):\n",
    "        layers = []\n",
    "        prev = input_dim\n",
    "        for h in self.hidden_layer_sizes:\n",
    "            layers.append(nn.Linear(prev, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev = h\n",
    "        layers.append(nn.Linear(prev, 1))\n",
    "        self.model_ = nn.Sequential(*layers).to(self.device)\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        rng = np.random.RandomState(self.random_state)\n",
    "        torch.manual_seed(self.random_state)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(self.random_state)\n",
    "\n",
    "        X = np.asarray(X, dtype=np.float32)\n",
    "        y = np.asarray(y, dtype=np.float32).reshape(-1, 1)\n",
    "        \n",
    "        # Handle sample weights\n",
    "        if sample_weight is not None:\n",
    "            sample_weight = np.asarray(sample_weight, dtype=np.float32).reshape(-1, 1)\n",
    "        else:\n",
    "            sample_weight = np.ones((len(X), 1), dtype=np.float32)\n",
    "\n",
    "        self.input_dim_ = X.shape[1]\n",
    "        self._build_model(self.input_dim_)\n",
    "\n",
    "        optimizer = optim.Adam(self.model_.parameters(), lr=self.learning_rate_init, weight_decay=self.alpha)\n",
    "\n",
    "        # internal validation split for early stopping\n",
    "        if self.early_stopping:\n",
    "            idx = rng.permutation(len(X))\n",
    "            split = int(len(X) * 0.9)\n",
    "            train_idx, val_idx = idx[:split], idx[split:]\n",
    "            X_tr, y_tr, w_tr = X[train_idx], y[train_idx], sample_weight[train_idx]\n",
    "            X_va, y_va, w_va = X[val_idx], y[val_idx], sample_weight[val_idx]\n",
    "        else:\n",
    "            X_tr, y_tr, w_tr = X, y, sample_weight\n",
    "            X_va, y_va, w_va = None, None, None\n",
    "\n",
    "        X_tr_t = torch.from_numpy(X_tr).to(self.device)\n",
    "        y_tr_t = torch.from_numpy(y_tr).to(self.device)\n",
    "        w_tr_t = torch.from_numpy(w_tr).to(self.device)\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        best_state = None\n",
    "        patience_left = self.patience\n",
    "\n",
    "        for epoch in range(self.max_epochs):\n",
    "            self.model_.train()\n",
    "            # mini-batch training with sample weights\n",
    "            perm = rng.permutation(len(X_tr_t))\n",
    "            for i in range(0, len(X_tr_t), self.batch_size):\n",
    "                batch_idx = perm[i:i+self.batch_size]\n",
    "                xb = X_tr_t[batch_idx]\n",
    "                yb = y_tr_t[batch_idx]\n",
    "                wb = w_tr_t[batch_idx]\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                logits = self.model_(xb)\n",
    "                # Weighted binary cross entropy\n",
    "                loss = nn.functional.binary_cross_entropy_with_logits(logits, yb, weight=wb)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            if self.early_stopping and X_va is not None:\n",
    "                self.model_.eval()\n",
    "                with torch.no_grad():\n",
    "                    X_va_t = torch.from_numpy(X_va).to(self.device)\n",
    "                    y_va_t = torch.from_numpy(y_va).to(self.device)\n",
    "                    w_va_t = torch.from_numpy(w_va).to(self.device)\n",
    "                    val_logits = self.model_(X_va_t)\n",
    "                    val_loss = nn.functional.binary_cross_entropy_with_logits(val_logits, y_va_t, weight=w_va_t).item()\n",
    "\n",
    "                if val_loss < best_val_loss - 1e-5:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_state = {k: v.clone() for k, v in self.model_.state_dict().items()}\n",
    "                    patience_left = self.patience\n",
    "                else:\n",
    "                    patience_left -= 1\n",
    "                    if patience_left <= 0:\n",
    "                        break\n",
    "\n",
    "        if best_state is not None:\n",
    "            self.model_.load_state_dict(best_state)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.asarray(X, dtype=np.float32)\n",
    "        self.model_.eval()\n",
    "        with torch.no_grad():\n",
    "            X_t = torch.from_numpy(X).to(self.device)\n",
    "            logits = self.model_(X_t)\n",
    "            probs_pos = torch.sigmoid(logits).cpu().numpy().ravel()\n",
    "        probs_neg = 1.0 - probs_pos\n",
    "        return np.column_stack([probs_neg, probs_pos])\n",
    "\n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)[:, 1]\n",
    "        return (proba >= 0.5).astype(int)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        y = np.asarray(y)\n",
    "        return (y_pred == y).mean()\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            'hidden_layer_sizes': self.hidden_layer_sizes,\n",
    "            'alpha': self.alpha,\n",
    "            'learning_rate_init': self.learning_rate_init,\n",
    "            'max_epochs': self.max_epochs,\n",
    "            'random_state': self.random_state,\n",
    "            'early_stopping': self.early_stopping,\n",
    "            'batch_size': self.batch_size,\n",
    "            'patience': self.patience,\n",
    "        }\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for k, v in params.items():\n",
    "            setattr(self, k, v)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['Workclass', 'Education', 'Occupation', 'interview_score', 'cv_assessment_score']\n",
      "X_train shape: (30000, 5)\n",
      "\n",
      "Training with SAMPLE WEIGHTS (applied to loss)...\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     51\u001b[39m clf = TorchBinaryMLP(\n\u001b[32m     52\u001b[39m     hidden_layer_sizes=hidden,\n\u001b[32m     53\u001b[39m     alpha=alpha,\n\u001b[32m   (...)\u001b[39m\u001b[32m     57\u001b[39m     early_stopping=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     58\u001b[39m )\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# sample_weight applies weights to the BCE loss function\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[43mclf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_processed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m score = clf.score(X_val_processed, y_val)\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m score > best_score:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 85\u001b[39m, in \u001b[36mTorchBinaryMLP.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m     82\u001b[39m wb = w_tr_t[batch_idx]\n\u001b[32m     84\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;66;03m# Weighted binary cross entropy\u001b[39;00m\n\u001b[32m     87\u001b[39m loss = nn.functional.binary_cross_entropy_with_logits(logits, yb, weight=wb)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\container.py:253\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    251\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Get sample weights for training (only if USE_WEIGHTED is True)\n",
    "if USE_WEIGHTED:\n",
    "    sample_weights = get_sample_weights(train_df, group_weights, target)\n",
    "else:\n",
    "    sample_weights = None\n",
    "\n",
    "# Remove protected characteristics from features\n",
    "cols_to_exclude = protected_characteristics + [target]\n",
    "features = [col for col in train_df.columns if col not in cols_to_exclude]\n",
    "\n",
    "# Create X/y splits\n",
    "X_train = train_df[features]\n",
    "y_train = train_df[target]\n",
    "X_val = val_df[features]\n",
    "y_val = val_df[target]\n",
    "X_test = test_df[features]\n",
    "y_test = test_df[target]\n",
    "\n",
    "print(f\"Features: {features}\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "\n",
    "categorical_cols = [col for col in ['Workclass', 'Education', 'Occupation'] if col in features]\n",
    "\n",
    "# All features should be numeric; scale them\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "# Preprocess data\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    # 'hidden_layer_sizes': [(64,), (128,), (64, 32), (128, 64)],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate_init': [0.001, 0.01]\n",
    "}\n",
    "\n",
    "best_score = 0.0\n",
    "best_params = {}\n",
    "\n",
    "print(f\"\\nTraining with {'SAMPLE WEIGHTS (applied to loss)' if USE_WEIGHTED else 'NO WEIGHTS'}...\\n\")\n",
    "\n",
    "for hidden in param_grid['hidden_layer_sizes']:\n",
    "    for alpha in param_grid['alpha']:\n",
    "        for lr in param_grid['learning_rate_init']:\n",
    "            clf = TorchBinaryMLP(\n",
    "                hidden_layer_sizes=hidden,\n",
    "                alpha=alpha,\n",
    "                learning_rate_init=lr,\n",
    "                max_epochs=500,\n",
    "                random_state=42,\n",
    "                early_stopping=True\n",
    "            )\n",
    "            # sample_weight applies weights to the BCE loss function\n",
    "            clf.fit(X_train_processed, y_train, sample_weight=sample_weights)\n",
    "            score = clf.score(X_val_processed, y_val)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_params = {'hidden_layer_sizes': hidden, 'alpha': alpha, 'learning_rate_init': lr}\n",
    "\n",
    "print(f\"Best params: {best_params}\")\n",
    "print(f\"Best validation accuracy: {best_score:.4f}\")\n",
    "\n",
    "# Train final model\n",
    "best_clf = TorchBinaryMLP(**best_params, max_epochs=500, random_state=42, early_stopping=True)\n",
    "best_clf.fit(X_train_processed, y_train, sample_weight=sample_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fairness Metric Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_with_preds = val_df.copy()\n",
    "val_with_preds['prediction'] = best_clf.predict(X_val_processed)\n",
    "\n",
    "# Compute equalized odds for binary race (white vs non-white)\n",
    "eo_ratio = equalized_odds(val_with_preds, pred_col='prediction', true_col=target)\n",
    "\n",
    "# Get detailed TPR/FPR by group\n",
    "val_with_preds['_race_binary'] = (val_with_preds['Race'] == 1).astype(int)\n",
    "results = {}\n",
    "for race in [0, 1]:\n",
    "    group_data = val_with_preds[val_with_preds['_race_binary'] == race]\n",
    "    \n",
    "    # Actual positives and negatives (based on true label)\n",
    "    actual_positives = group_data[group_data[target] == 1]\n",
    "    actual_negatives = group_data[group_data[target] == 0]\n",
    "    \n",
    "    race_name = \"white\" if race == 1 else \"non-white\"\n",
    "    results[race_name] = {\n",
    "        # TPR: of actual positives, fraction predicted positive\n",
    "        'tpr': float(actual_positives['prediction'].mean()) if len(actual_positives) > 0 else None,\n",
    "        # FPR: of actual negatives, fraction predicted positive\n",
    "        'fpr': float(actual_negatives['prediction'].mean()) if len(actual_negatives) > 0 else None,\n",
    "        'count': len(group_data)\n",
    "    }\n",
    "\n",
    "print(\"Fairness Metrics (Neural Network) - Binary Race:\")\n",
    "print(f\"\\nEqualized Odds Ratio: {eo_ratio:.4f}\")\n",
    "print(\"\\nBy Group:\")\n",
    "for group, metrics in results.items():\n",
    "    print(f\"  {group}: TPR={metrics['tpr']:.4f}, FPR={metrics['fpr']:.4f}, Count={metrics['count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ROC Curve Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_proba = best_clf.predict_proba(X_val_processed)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_proba)\n",
    "auc_score = roc_auc_score(y_val, y_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'Neural Network (AUC = {auc_score:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Neural Network')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC Score: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Adjusted Equalized Odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjusted_equalized_odds(data, y_true_col, y_proba, thresholds):\n",
    "    \"\"\"\n",
    "    Calculate equalized odds using group-specific classification thresholds.\n",
    "    Uses binary race: white (Race==1) vs non-white (Race!=1).\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame with Race column and true labels\n",
    "        y_true_col: Name of true label column\n",
    "        y_proba: Array of predicted probabilities\n",
    "        thresholds: Dict mapping race_binary (0 or 1) to classification threshold\n",
    "                    e.g., {0: 0.4, 1: 0.6} means non-white uses 0.4, white uses 0.6\n",
    "    \n",
    "    Returns:\n",
    "        Dict with TPR/FPR per group and equalized odds ratio\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    data['y_proba'] = y_proba\n",
    "    data['_race_binary'] = (data['Race'] == 1).astype(int)\n",
    "    \n",
    "    # Apply group-specific thresholds\n",
    "    data['adjusted_pred'] = data.apply(\n",
    "        lambda row: 1 if row['y_proba'] >= thresholds.get(row['_race_binary'], 0.5) else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    tpr_rates = []\n",
    "    fpr_rates = []\n",
    "    results = {}\n",
    "    \n",
    "    for race in [0, 1]:  # 0=non-white, 1=white\n",
    "        group_data = data[data['_race_binary'] == race]\n",
    "        actual_positives = group_data[group_data[y_true_col] == 1]\n",
    "        actual_negatives = group_data[group_data[y_true_col] == 0]\n",
    "        \n",
    "        tpr = actual_positives['adjusted_pred'].mean() if len(actual_positives) > 0 else 0\n",
    "        fpr = actual_negatives['adjusted_pred'].mean() if len(actual_negatives) > 0 else 0\n",
    "        \n",
    "        tpr_rates.append(tpr)\n",
    "        fpr_rates.append(fpr)\n",
    "        \n",
    "        race_name = \"white\" if race == 1 else \"non-white\"\n",
    "        results[race_name] = {\n",
    "            'tpr': float(tpr),\n",
    "            'fpr': float(fpr),\n",
    "            'threshold': float(thresholds.get(race, 0.5)),\n",
    "            'count': int(len(group_data))\n",
    "        }\n",
    "    \n",
    "    max_tpr, min_tpr = max(tpr_rates), min(tpr_rates)\n",
    "    max_fpr, min_fpr = max(fpr_rates), min(fpr_rates)\n",
    "    \n",
    "    tpr_ratio = max_tpr / min_tpr if min_tpr > 0 else float('inf')\n",
    "    fpr_ratio = max_fpr / min_fpr if min_fpr > 0 else float('inf')\n",
    "    \n",
    "    results['tpr_ratio'] = float(tpr_ratio)\n",
    "    results['fpr_ratio'] = float(fpr_ratio)\n",
    "    results['equalized_odds_ratio'] = float(max(tpr_ratio, fpr_ratio))\n",
    "    \n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
